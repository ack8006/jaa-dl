{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/abhishekkadian/Documents/Github/jaa-dl/assignment-1\")\n",
    "sys.path.append(\"/Users/abhishekkadian/Documents/Github/jaa-dl/assignment-1/ladder/ladder-ak/\")\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "\n",
    "import ladder\n",
    "import encoder\n",
    "import decoder\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ladder = reload(ladder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_decoder_grad(temp_decoder):\n",
    "    def sum_grad(v):\n",
    "        return torch.sum(torch.abs(v))\n",
    "    gg = sum_grad(temp_decoder.a1.grad) + sum_grad(temp_decoder.a2.grad) + sum_grad(temp_decoder.a3.grad) + \\\n",
    "            sum_grad(temp_decoder.a4.grad) + sum_grad(temp_decoder.a5.grad) + \\\n",
    "            sum_grad(temp_decoder.a6.grad) + sum_grad(temp_decoder.a7.grad) + sum_grad(temp_decoder.a8.grad) + \\\n",
    "            sum_grad(temp_decoder.a9.grad) + sum_grad(temp_decoder.a10.grad)\n",
    "    return gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "with open(\"data/train_labeled.p\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open(\"data/train_unlabeled.p\") as f:\n",
    "    unlabeled_dataset = pickle.load(f)\n",
    "unlabeled_dataset.train_labels = torch.LongTensor(\n",
    "    [-1 for x in range(unlabeled_dataset.train_data.size()[0])])\n",
    "with open(\"data/validation.p\") as f:\n",
    "    valid_dataset = pickle.load(f)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "unlabeled_loader = torch.utils.data.DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labelled_data = []\n",
    "for data, target in train_loader:\n",
    "    train_labelled_data.append((data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated code\n"
     ]
    }
   ],
   "source": [
    "noise_std = 0.2\n",
    "epochs = 1\n",
    "\n",
    "encoder_in = 28 * 28\n",
    "decoder_in = 10\n",
    "encoder_sizes = [1000, 500, 250, 250, 250, decoder_in]\n",
    "decoder_sizes = [250, 250, 250, 500, 1000, encoder_in]\n",
    "unsupervised_costs_lambda = [0.1, 0.1, 0.1, 0.1, 0.1, 20., 2000.]\n",
    "\n",
    "encoder_activations = [\"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"softmax\"]\n",
    "encoder_train_bn_scaling = [False, False, False, False, False, True]\n",
    "encoder_bias = [False, False, False, False, False, False]\n",
    "\n",
    "mnist_ladder = ladder.Ladder(encoder_in, encoder_sizes, decoder_in, decoder_sizes, encoder_in,\n",
    "                encoder_activations, encoder_train_bn_scaling, encoder_bias, noise_std)\n",
    "\n",
    "optimizer = Adam(mnist_ladder.parameters(), lr=0.002)\n",
    "loss_labelled = torch.nn.CrossEntropyLoss()\n",
    "loss_unsupervised = torch.nn.MSELoss()\n",
    "\n",
    "grad_decoder_a_updates = []\n",
    "history_unsupervised_cost = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    agg_cost = 0.\n",
    "    agg_supervised_cost = 0.\n",
    "    agg_unsupervised_cost = 0.\n",
    "    num_batches = 0\n",
    "\n",
    "    # Training\n",
    "    mnist_ladder.train()\n",
    "\n",
    "    ind_labelled = 0\n",
    "\n",
    "    for batch_idx, (unlabeled_data, unlabeled_target) in enumerate(unlabeled_loader):\n",
    "        # Labelled data\n",
    "        if ind_labelled == len(train_labelled_data):\n",
    "            # reset counter\n",
    "            random.shuffle(train_labelled_data)\n",
    "            ind_labelled = 0\n",
    "        labelled_data = train_labelled_data[ind_labelled][0]\n",
    "        labelled_target = train_labelled_data[ind_labelled][1]\n",
    "        ind_labelled += 1\n",
    "\n",
    "        labelled_data_size = labelled_data.size()[0]\n",
    "\n",
    "        data = np.concatenate((labelled_data.numpy(), unlabeled_data.numpy()), axis=0)\n",
    "        target = np.concatenate((labelled_target.numpy(), unlabeled_target.numpy()), axis=0)\n",
    "\n",
    "        data = torch.FloatTensor(data)\n",
    "        target = torch.LongTensor(target)\n",
    "\n",
    "        data = data[:,0,:,:].numpy()\n",
    "        data = data.reshape(data.shape[0], 28 * 28)\n",
    "        data = torch.FloatTensor(data)\n",
    "        # TODO: Hold off on this, things should work right now because LongTensor is only used for cost.\n",
    "        # TODO: Change from LongTensor to FloatTensor. Autograd has a bug with LongTensor.\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # Pass data through the network\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # do a noisy pass\n",
    "        output_noise = mnist_ladder.forward_encoders_noise(data)\n",
    "        tilde_z_layers = mnist_ladder.get_encoders_tilde_z(reverse=True)\n",
    "\n",
    "        # do a clean pass\n",
    "        _ = mnist_ladder.forward_encoders_clean(data)\n",
    "        z_pre_layers = mnist_ladder.get_encoders_z_pre(reverse=True)\n",
    "        z_layers = mnist_ladder.get_encoders_z(reverse=True)\n",
    "\n",
    "        # pass through decoders\n",
    "        hat_z_layers = mnist_ladder.forward_decoders(tilde_z_layers, output_noise)\n",
    "\n",
    "        z_pre_layers.append(data)\n",
    "\n",
    "        # TODO: Verify if you have to batch-normalize the bottom-most layer also\n",
    "\n",
    "        # batch normalizing the image also for cost comparison\n",
    "        bn_data = data\n",
    "#         bn_data = mnist_ladder.bn_input_image(data)\n",
    "        z_layers.append(bn_data)\n",
    "\n",
    "        # batch normalize using mean, var of z_pre\n",
    "        bn_hat_z_layers = mnist_ladder.decoder_bn_hat_z_layers(hat_z_layers, z_pre_layers)\n",
    "\n",
    "        assert len(z_layers) == len(bn_hat_z_layers)\n",
    "\n",
    "        # calculate costs\n",
    "        cost_supervised = loss_labelled.forward(output_noise[:labelled_data_size], target[:labelled_data_size])\n",
    "        cost_unsupervised = 0.\n",
    "        u_cost_history = []\n",
    "        for cost_lambda, z, bn_hat_z in zip(unsupervised_costs_lambda, z_layers, bn_hat_z_layers):\n",
    "            c = cost_lambda * loss_unsupervised.forward(bn_hat_z, z)\n",
    "            u_cost_history.append(c.data[0])\n",
    "            cost_unsupervised += c\n",
    "        history_unsupervised_cost.append(u_cost_history)\n",
    "\n",
    "        # backprop\n",
    "        cost = cost_supervised + cost_unsupervised\n",
    "        cost.backward()\n",
    "\n",
    "        agg_cost += cost.data[0]\n",
    "        agg_supervised_cost += cost_supervised.data[0]\n",
    "        agg_unsupervised_cost += cost_unsupervised.data[0]\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_batches += 1\n",
    "        \n",
    "#         print(\"BREAKING EARLY\")\n",
    "#         break\n",
    "\n",
    "        if ind_labelled == len(train_labelled_data):\n",
    "            # Evaluation\n",
    "            mnist_ladder.eval()\n",
    "            ladder.evaluate_performance(mnist_ladder, agg_cost, agg_supervised_cost, agg_unsupervised_cost, \n",
    "                                        num_batches, valid_loader, e, ind_labelled)\n",
    "            # reset costs\n",
    "            agg_cost = 0.\n",
    "            agg_supervised_cost = 0.\n",
    "            agg_unsupervised_cost = 0.\n",
    "            num_batches = 0\n",
    "            mnist_ladder.train()\n",
    "            \n",
    "            print(\"BREAKING BAD\")\n",
    "            break\n",
    "\n",
    "    # Evaluation\n",
    "#     mnist_ladder.eval()\n",
    "#     ladder.evaluate_performance(mnist_ladder, agg_cost, agg_supervised_cost, agg_unsupervised_cost,\n",
    "#                                 num_batches, valid_loader, e, ind_labelled)\n",
    "#     mnist_ladder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bn = torch.nn.BatchNorm1d(28 * 28, affine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(np.isclose(test_bn(data)[0].data.numpy(), z_layers[-1][0].data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.16994230449199677,\n",
       "  0.1520533412694931,\n",
       "  0.1463761180639267,\n",
       "  0.1488255113363266,\n",
       "  0.1513332575559616,\n",
       "  30.847654342651367,\n",
       "  13232826.0],\n",
       " [0.16386182606220245,\n",
       "  0.15012489259243011,\n",
       "  0.14290332794189453,\n",
       "  0.14446774125099182,\n",
       "  0.14567382633686066,\n",
       "  28.7259521484375,\n",
       "  12357650.0],\n",
       " [0.15061624348163605,\n",
       "  0.14993156492710114,\n",
       "  0.14054004848003387,\n",
       "  0.14280438423156738,\n",
       "  0.1462474912405014,\n",
       "  28.913280487060547,\n",
       "  12149988.0],\n",
       " [0.15210600197315216,\n",
       "  0.14606966078281403,\n",
       "  0.14262360334396362,\n",
       "  0.14077530801296234,\n",
       "  0.14304779469966888,\n",
       "  29.01106834411621,\n",
       "  12292043.0],\n",
       " [0.1483362466096878,\n",
       "  0.14977838099002838,\n",
       "  0.14246797561645508,\n",
       "  0.1424437314271927,\n",
       "  0.14406244456768036,\n",
       "  28.421552658081055,\n",
       "  11945292.0],\n",
       " [0.1515161246061325,\n",
       "  0.1453167051076889,\n",
       "  0.14033059775829315,\n",
       "  0.13503269851207733,\n",
       "  0.13935911655426025,\n",
       "  27.929964065551758,\n",
       "  12456930.0],\n",
       " [0.148350790143013,\n",
       "  0.14249779284000397,\n",
       "  0.13850311934947968,\n",
       "  0.13731789588928223,\n",
       "  0.13538533449172974,\n",
       "  28.99725341796875,\n",
       "  11272838.0],\n",
       " [0.13480184972286224,\n",
       "  0.13806627690792084,\n",
       "  0.1355866938829422,\n",
       "  0.1311308592557907,\n",
       "  0.13164205849170685,\n",
       "  29.14554786682129,\n",
       "  12160784.0],\n",
       " [0.14508067071437836,\n",
       "  0.13758781552314758,\n",
       "  0.13485543429851532,\n",
       "  0.1316312700510025,\n",
       "  0.13156470656394958,\n",
       "  28.74915885925293,\n",
       "  11001401.0],\n",
       " [0.1424752026796341,\n",
       "  0.13719327747821808,\n",
       "  0.13627445697784424,\n",
       "  0.1296013444662094,\n",
       "  0.1252685934305191,\n",
       "  27.95736312866211,\n",
       "  11431275.0],\n",
       " [0.1436820775270462,\n",
       "  0.13503746688365936,\n",
       "  0.13439100980758667,\n",
       "  0.12856784462928772,\n",
       "  0.12585879862308502,\n",
       "  27.31039047241211,\n",
       "  10419145.0],\n",
       " [0.13914620876312256,\n",
       "  0.13479474186897278,\n",
       "  0.13573357462882996,\n",
       "  0.1255389153957367,\n",
       "  0.12187813967466354,\n",
       "  26.9788818359375,\n",
       "  10739442.0],\n",
       " [0.13026699423789978,\n",
       "  0.12614168226718903,\n",
       "  0.1267661303281784,\n",
       "  0.12162277847528458,\n",
       "  0.12092125415802002,\n",
       "  27.71375274658203,\n",
       "  10456371.0],\n",
       " [0.12895898520946503,\n",
       "  0.13088853657245636,\n",
       "  0.13209012150764465,\n",
       "  0.12362336367368698,\n",
       "  0.12033815681934357,\n",
       "  27.6601505279541,\n",
       "  9869418.0],\n",
       " [0.1232888251543045,\n",
       "  0.12947188317775726,\n",
       "  0.1322869509458542,\n",
       "  0.12342393398284912,\n",
       "  0.12264158576726913,\n",
       "  26.725969314575195,\n",
       "  9838073.0],\n",
       " [0.12583014369010925,\n",
       "  0.13190408051013947,\n",
       "  0.13439328968524933,\n",
       "  0.1238584890961647,\n",
       "  0.12236586958169937,\n",
       "  27.950382232666016,\n",
       "  10004823.0],\n",
       " [0.11891279369592667,\n",
       "  0.12640471756458282,\n",
       "  0.12717615067958832,\n",
       "  0.12064041942358017,\n",
       "  0.1237349659204483,\n",
       "  28.245738983154297,\n",
       "  8722562.0],\n",
       " [0.12097419798374176,\n",
       "  0.13228477537631989,\n",
       "  0.13529419898986816,\n",
       "  0.12146367132663727,\n",
       "  0.12096130102872849,\n",
       "  28.962594985961914,\n",
       "  9332545.0],\n",
       " [0.12134821712970734,\n",
       "  0.1310403198003769,\n",
       "  0.13380615413188934,\n",
       "  0.12014275044202805,\n",
       "  0.11747492849826813,\n",
       "  26.834197998046875,\n",
       "  8607238.0],\n",
       " [0.12238772213459015,\n",
       "  0.1325402557849884,\n",
       "  0.13626569509506226,\n",
       "  0.12164858728647232,\n",
       "  0.11940236389636993,\n",
       "  28.05965232849121,\n",
       "  9350697.0],\n",
       " [0.11796405166387558,\n",
       "  0.1345645636320114,\n",
       "  0.13725599646568298,\n",
       "  0.12194233387708664,\n",
       "  0.11918189376592636,\n",
       "  27.21005630493164,\n",
       "  9569855.0],\n",
       " [0.11080598831176758,\n",
       "  0.12824170291423798,\n",
       "  0.1297389417886734,\n",
       "  0.11818790435791016,\n",
       "  0.11782179027795792,\n",
       "  27.47358512878418,\n",
       "  8531867.0],\n",
       " [0.11288588494062424,\n",
       "  0.13221509754657745,\n",
       "  0.13189451396465302,\n",
       "  0.11971890926361084,\n",
       "  0.1199304610490799,\n",
       "  27.702486038208008,\n",
       "  8626304.0],\n",
       " [0.1122211366891861,\n",
       "  0.12990538775920868,\n",
       "  0.13197380304336548,\n",
       "  0.11959302425384521,\n",
       "  0.11850529909133911,\n",
       "  27.790128707885742,\n",
       "  8679630.0],\n",
       " [0.11648265272378922,\n",
       "  0.13057063519954681,\n",
       "  0.1336158961057663,\n",
       "  0.12170606851577759,\n",
       "  0.1190841794013977,\n",
       "  27.909561157226562,\n",
       "  8530269.0],\n",
       " [0.11596424877643585,\n",
       "  0.125571608543396,\n",
       "  0.12867389619350433,\n",
       "  0.11714936792850494,\n",
       "  0.1155167818069458,\n",
       "  27.383718490600586,\n",
       "  7878505.0],\n",
       " [0.12051588296890259,\n",
       "  0.12782450020313263,\n",
       "  0.13213558495044708,\n",
       "  0.12418105453252792,\n",
       "  0.12101227045059204,\n",
       "  28.806419372558594,\n",
       "  7831470.0],\n",
       " [0.1150631234049797,\n",
       "  0.1248849630355835,\n",
       "  0.13037391006946564,\n",
       "  0.12063892930746078,\n",
       "  0.11696799844503403,\n",
       "  29.099092483520508,\n",
       "  7896248.5],\n",
       " [0.11535988003015518,\n",
       "  0.12483619898557663,\n",
       "  0.1304416060447693,\n",
       "  0.12114068120718002,\n",
       "  0.11644693464040756,\n",
       "  29.958274841308594,\n",
       "  7685003.5],\n",
       " [0.1159748062491417,\n",
       "  0.12526535987854004,\n",
       "  0.12994180619716644,\n",
       "  0.11945140361785889,\n",
       "  0.11522569507360458,\n",
       "  29.624855041503906,\n",
       "  7759462.5],\n",
       " [0.11820489168167114,\n",
       "  0.12601684033870697,\n",
       "  0.1318850964307785,\n",
       "  0.12331600487232208,\n",
       "  0.11716953665018082,\n",
       "  31.869888305664062,\n",
       "  7613066.5],\n",
       " [0.11705134063959122,\n",
       "  0.12526695430278778,\n",
       "  0.1288580298423767,\n",
       "  0.11950712651014328,\n",
       "  0.11363362520933151,\n",
       "  30.23869514465332,\n",
       "  6618195.5],\n",
       " [0.11819960922002792,\n",
       "  0.1277511715888977,\n",
       "  0.13391606509685516,\n",
       "  0.12276710569858551,\n",
       "  0.11469731479883194,\n",
       "  32.432559967041016,\n",
       "  7026890.0],\n",
       " [0.1188693642616272,\n",
       "  0.12769803404808044,\n",
       "  0.13689693808555603,\n",
       "  0.12510532140731812,\n",
       "  0.11545121669769287,\n",
       "  32.508235931396484,\n",
       "  6911108.0],\n",
       " [0.11958672106266022,\n",
       "  0.12332457304000854,\n",
       "  0.13279516994953156,\n",
       "  0.1213439479470253,\n",
       "  0.11231676489114761,\n",
       "  30.62229347229004,\n",
       "  6971357.0],\n",
       " [0.12034515291452408,\n",
       "  0.12528279423713684,\n",
       "  0.1348550170660019,\n",
       "  0.1229897141456604,\n",
       "  0.11361602693796158,\n",
       "  31.94963264465332,\n",
       "  6417453.5],\n",
       " [0.11980950087308884,\n",
       "  0.12434025853872299,\n",
       "  0.134187251329422,\n",
       "  0.12619076669216156,\n",
       "  0.11596355587244034,\n",
       "  31.307899475097656,\n",
       "  6386175.5],\n",
       " [0.12126802653074265,\n",
       "  0.12579411268234253,\n",
       "  0.1360623836517334,\n",
       "  0.12540189921855927,\n",
       "  0.11499052494764328,\n",
       "  30.29450225830078,\n",
       "  6050212.0],\n",
       " [0.12316472828388214,\n",
       "  0.12688730657100677,\n",
       "  0.13625718653202057,\n",
       "  0.1245139017701149,\n",
       "  0.1127266064286232,\n",
       "  30.586952209472656,\n",
       "  5858106.0],\n",
       " [0.12629762291908264,\n",
       "  0.12817053496837616,\n",
       "  0.13802388310432434,\n",
       "  0.12859387695789337,\n",
       "  0.11612247675657272,\n",
       "  32.51222229003906,\n",
       "  5761375.0],\n",
       " [0.12204625457525253,\n",
       "  0.12467342615127563,\n",
       "  0.134418323636055,\n",
       "  0.12735380232334137,\n",
       "  0.11564967781305313,\n",
       "  30.395282745361328,\n",
       "  5884210.0],\n",
       " [0.13405945897102356,\n",
       "  0.1319705992937088,\n",
       "  0.14508162438869476,\n",
       "  0.13311491906642914,\n",
       "  0.11672002077102661,\n",
       "  32.45560836791992,\n",
       "  5749811.0],\n",
       " [0.12746307253837585,\n",
       "  0.12652216851711273,\n",
       "  0.1380082219839096,\n",
       "  0.12766781449317932,\n",
       "  0.11345227807760239,\n",
       "  31.215373992919922,\n",
       "  5672731.0],\n",
       " [0.12841622531414032,\n",
       "  0.12893030047416687,\n",
       "  0.14139391481876373,\n",
       "  0.1315092146396637,\n",
       "  0.11799750477075577,\n",
       "  34.098304748535156,\n",
       "  5332557.0],\n",
       " [0.12658074498176575,\n",
       "  0.12812553346157074,\n",
       "  0.1399281769990921,\n",
       "  0.12812864780426025,\n",
       "  0.11336815357208252,\n",
       "  32.119747161865234,\n",
       "  4950101.5],\n",
       " [0.1293380707502365,\n",
       "  0.131185382604599,\n",
       "  0.14381657540798187,\n",
       "  0.13327686488628387,\n",
       "  0.11677161604166031,\n",
       "  34.611114501953125,\n",
       "  5195389.5],\n",
       " [0.13182036578655243,\n",
       "  0.13016782701015472,\n",
       "  0.14338235557079315,\n",
       "  0.13221508264541626,\n",
       "  0.11569087952375412,\n",
       "  32.775081634521484,\n",
       "  5527991.0],\n",
       " [0.12491209805011749,\n",
       "  0.12679535150527954,\n",
       "  0.13899146020412445,\n",
       "  0.13006462156772614,\n",
       "  0.1165175661444664,\n",
       "  33.83828353881836,\n",
       "  4946961.0],\n",
       " [0.12321078777313232,\n",
       "  0.12584619224071503,\n",
       "  0.1410457342863083,\n",
       "  0.13437765836715698,\n",
       "  0.11564910411834717,\n",
       "  34.54155731201172,\n",
       "  5132801.0],\n",
       " [0.1211620569229126,\n",
       "  0.12674854695796967,\n",
       "  0.1395769864320755,\n",
       "  0.13299550116062164,\n",
       "  0.11748107522726059,\n",
       "  30.761964797973633,\n",
       "  5144764.0],\n",
       " [0.12296298891305923,\n",
       "  0.12705595791339874,\n",
       "  0.13865481317043304,\n",
       "  0.1327933371067047,\n",
       "  0.11612359434366226,\n",
       "  31.93073081970215,\n",
       "  5094478.5],\n",
       " [0.12077170610427856,\n",
       "  0.12481211870908737,\n",
       "  0.1352122724056244,\n",
       "  0.13159364461898804,\n",
       "  0.11478465795516968,\n",
       "  32.40642166137695,\n",
       "  4727906.0],\n",
       " [0.12247198075056076,\n",
       "  0.1285414695739746,\n",
       "  0.14105698466300964,\n",
       "  0.13189224898815155,\n",
       "  0.11632756143808365,\n",
       "  31.736419677734375,\n",
       "  4492792.0],\n",
       " [0.11969474703073502,\n",
       "  0.12544649839401245,\n",
       "  0.13332349061965942,\n",
       "  0.12953869998455048,\n",
       "  0.11465511471033096,\n",
       "  31.434635162353516,\n",
       "  4763737.0],\n",
       " [0.12668578326702118,\n",
       "  0.131876602768898,\n",
       "  0.1434398740530014,\n",
       "  0.13390694558620453,\n",
       "  0.11668477207422256,\n",
       "  29.97789764404297,\n",
       "  4531906.0],\n",
       " [0.12309753894805908,\n",
       "  0.12960538268089294,\n",
       "  0.1391134113073349,\n",
       "  0.13080649077892303,\n",
       "  0.11600493639707565,\n",
       "  30.970413208007812,\n",
       "  4234003.5],\n",
       " [0.1202392578125,\n",
       "  0.12606875598430634,\n",
       "  0.1345398873090744,\n",
       "  0.13220630586147308,\n",
       "  0.11542618274688721,\n",
       "  29.883468627929688,\n",
       "  4204720.0],\n",
       " [0.1244637593626976,\n",
       "  0.13232283294200897,\n",
       "  0.14437654614448547,\n",
       "  0.1351274847984314,\n",
       "  0.11698796600103378,\n",
       "  31.25917625427246,\n",
       "  4393130.0],\n",
       " [0.12211950123310089,\n",
       "  0.12820546329021454,\n",
       "  0.1402868628501892,\n",
       "  0.13627173006534576,\n",
       "  0.11691068857908249,\n",
       "  33.02804946899414,\n",
       "  3967683.0],\n",
       " [0.12028483301401138,\n",
       "  0.1251242458820343,\n",
       "  0.1328859031200409,\n",
       "  0.13080482184886932,\n",
       "  0.11474978923797607,\n",
       "  31.792776107788086,\n",
       "  4092211.75],\n",
       " [0.13023386895656586,\n",
       "  0.1365738958120346,\n",
       "  0.15277111530303955,\n",
       "  0.1403224617242813,\n",
       "  0.11792302131652832,\n",
       "  31.789180755615234,\n",
       "  3836352.75],\n",
       " [0.12658046185970306,\n",
       "  0.13140635192394257,\n",
       "  0.1410791426897049,\n",
       "  0.13563060760498047,\n",
       "  0.11473999172449112,\n",
       "  29.539730072021484,\n",
       "  3737892.75],\n",
       " [0.11995532363653183,\n",
       "  0.12723122537136078,\n",
       "  0.1341620236635208,\n",
       "  0.13432997465133667,\n",
       "  0.11558913439512253,\n",
       "  34.133480072021484,\n",
       "  3837456.0],\n",
       " [0.12567631900310516,\n",
       "  0.12989699840545654,\n",
       "  0.13748589158058167,\n",
       "  0.1364378184080124,\n",
       "  0.11548855155706406,\n",
       "  30.90747833251953,\n",
       "  3879827.5],\n",
       " [0.12398741394281387,\n",
       "  0.13176262378692627,\n",
       "  0.14397881925106049,\n",
       "  0.14451183378696442,\n",
       "  0.11719038337469101,\n",
       "  30.192468643188477,\n",
       "  3875240.25],\n",
       " [0.12147330492734909,\n",
       "  0.12712852656841278,\n",
       "  0.13293910026550293,\n",
       "  0.13730479776859283,\n",
       "  0.11547285318374634,\n",
       "  30.6865234375,\n",
       "  3410287.5],\n",
       " [0.12321615219116211,\n",
       "  0.13015268743038177,\n",
       "  0.14128470420837402,\n",
       "  0.13905034959316254,\n",
       "  0.11628033220767975,\n",
       "  29.511150360107422,\n",
       "  3609585.25],\n",
       " [0.12479352205991745,\n",
       "  0.1315842717885971,\n",
       "  0.14281800389289856,\n",
       "  0.14476045966148376,\n",
       "  0.11625983566045761,\n",
       "  29.230134963989258,\n",
       "  3139968.75],\n",
       " [0.1298634558916092,\n",
       "  0.1362384557723999,\n",
       "  0.15052922070026398,\n",
       "  0.14848391711711884,\n",
       "  0.11858534067869186,\n",
       "  29.889602661132812,\n",
       "  3364771.75],\n",
       " [0.12542963027954102,\n",
       "  0.13000833988189697,\n",
       "  0.14352835714817047,\n",
       "  0.14407655596733093,\n",
       "  0.11598185449838638,\n",
       "  29.83987808227539,\n",
       "  3345374.0],\n",
       " [0.12546032667160034,\n",
       "  0.1284831017255783,\n",
       "  0.14186275005340576,\n",
       "  0.1447763890028,\n",
       "  0.11691208928823471,\n",
       "  29.15208625793457,\n",
       "  3367384.75],\n",
       " [0.13095666468143463,\n",
       "  0.1359025090932846,\n",
       "  0.15345989167690277,\n",
       "  0.14727075397968292,\n",
       "  0.11674028635025024,\n",
       "  28.6959171295166,\n",
       "  3188424.25],\n",
       " [0.13109056651592255,\n",
       "  0.13628993928432465,\n",
       "  0.15263712406158447,\n",
       "  0.1484539955854416,\n",
       "  0.11702980101108551,\n",
       "  27.309606552124023,\n",
       "  2929225.0],\n",
       " [0.13520438969135284,\n",
       "  0.13618187606334686,\n",
       "  0.15321403741836548,\n",
       "  0.1437915712594986,\n",
       "  0.1156662255525589,\n",
       "  28.836565017700195,\n",
       "  2891152.0],\n",
       " [0.13490821421146393,\n",
       "  0.13776801526546478,\n",
       "  0.15521863102912903,\n",
       "  0.15157337486743927,\n",
       "  0.11779008060693741,\n",
       "  28.100414276123047,\n",
       "  2733311.5],\n",
       " [0.1316460371017456,\n",
       "  0.13594551384449005,\n",
       "  0.1537502557039261,\n",
       "  0.14478163421154022,\n",
       "  0.11688586324453354,\n",
       "  28.052642822265625,\n",
       "  2895892.25],\n",
       " [0.1395045667886734,\n",
       "  0.14259441196918488,\n",
       "  0.15923500061035156,\n",
       "  0.14510749280452728,\n",
       "  0.11618638038635254,\n",
       "  29.05106544494629,\n",
       "  2709067.0],\n",
       " [0.135611429810524,\n",
       "  0.14004038274288177,\n",
       "  0.15591953694820404,\n",
       "  0.144071564078331,\n",
       "  0.11655908077955246,\n",
       "  28.062498092651367,\n",
       "  2840974.75],\n",
       " [0.14154216647148132,\n",
       "  0.14045988023281097,\n",
       "  0.15606997907161713,\n",
       "  0.14843153953552246,\n",
       "  0.1167006865143776,\n",
       "  28.136594772338867,\n",
       "  2772513.5],\n",
       " [0.13259604573249817,\n",
       "  0.1357525736093521,\n",
       "  0.15481719374656677,\n",
       "  0.14338622987270355,\n",
       "  0.1161828264594078,\n",
       "  27.57745361328125,\n",
       "  2658622.5],\n",
       " [0.1262190043926239,\n",
       "  0.13474935293197632,\n",
       "  0.15642301738262177,\n",
       "  0.14673446118831635,\n",
       "  0.11691099405288696,\n",
       "  27.365896224975586,\n",
       "  2403643.0],\n",
       " [0.12916840612888336,\n",
       "  0.13470979034900665,\n",
       "  0.152754008769989,\n",
       "  0.1434902846813202,\n",
       "  0.11620680242776871,\n",
       "  26.339218139648438,\n",
       "  2556306.5],\n",
       " [0.13958919048309326,\n",
       "  0.14792171120643616,\n",
       "  0.16553834080696106,\n",
       "  0.15322355926036835,\n",
       "  0.11780720204114914,\n",
       "  28.3040828704834,\n",
       "  2475861.25],\n",
       " [0.13837584853172302,\n",
       "  0.1450154036283493,\n",
       "  0.16663400828838348,\n",
       "  0.150870680809021,\n",
       "  0.11750387400388718,\n",
       "  27.29791259765625,\n",
       "  2440426.75],\n",
       " [0.12383649498224258,\n",
       "  0.12587681412696838,\n",
       "  0.14416877925395966,\n",
       "  0.13501952588558197,\n",
       "  0.11530973762273788,\n",
       "  28.17197608947754,\n",
       "  2486326.25],\n",
       " [0.12762349843978882,\n",
       "  0.13410122692584991,\n",
       "  0.15672069787979126,\n",
       "  0.1441822499036789,\n",
       "  0.11479482799768448,\n",
       "  27.820045471191406,\n",
       "  2886652.25],\n",
       " [0.1253233700990677,\n",
       "  0.12739071249961853,\n",
       "  0.1504288911819458,\n",
       "  0.13932713866233826,\n",
       "  0.11676981300115585,\n",
       "  26.981027603149414,\n",
       "  2198966.0],\n",
       " [0.1255558431148529,\n",
       "  0.1294008046388626,\n",
       "  0.15465174615383148,\n",
       "  0.14675593376159668,\n",
       "  0.11704075336456299,\n",
       "  27.755142211914062,\n",
       "  2095525.125],\n",
       " [0.11966311931610107,\n",
       "  0.1236826553940773,\n",
       "  0.14403818547725677,\n",
       "  0.13749246299266815,\n",
       "  0.11537684500217438,\n",
       "  29.285259246826172,\n",
       "  2455871.5],\n",
       " [0.1251562088727951,\n",
       "  0.133572056889534,\n",
       "  0.1580238789319992,\n",
       "  0.14584162831306458,\n",
       "  0.11509104073047638,\n",
       "  29.12491226196289,\n",
       "  2296451.25],\n",
       " [0.12831752002239227,\n",
       "  0.1375858634710312,\n",
       "  0.16492249071598053,\n",
       "  0.15267686545848846,\n",
       "  0.11819853633642197,\n",
       "  28.836145401000977,\n",
       "  2228313.5],\n",
       " [0.12144865840673447,\n",
       "  0.12701204419136047,\n",
       "  0.15131117403507233,\n",
       "  0.13767389953136444,\n",
       "  0.11346540600061417,\n",
       "  26.908205032348633,\n",
       "  2549076.0],\n",
       " [0.12827546894550323,\n",
       "  0.13290230929851532,\n",
       "  0.15649910271167755,\n",
       "  0.14333438873291016,\n",
       "  0.11501767486333847,\n",
       "  27.529781341552734,\n",
       "  2223181.25],\n",
       " [0.12113644927740097,\n",
       "  0.1264214962720871,\n",
       "  0.1493729203939438,\n",
       "  0.13837246596813202,\n",
       "  0.11421524733304977,\n",
       "  26.025800704956055,\n",
       "  2106061.25]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_unsupervised_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
