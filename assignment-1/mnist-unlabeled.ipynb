{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle \n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.ones((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  2.,  2.,  2.],\n",
       "       [ 2.,  2.,  2.,  2.],\n",
       "       [ 2.,  2.,  2.,  2.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size at /Users/soumith/anaconda/conda-bld/pytorch-0.1.8_1486027042839/work/torch/lib/TH/generic/THTensorMath.c:601",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-090f22a11066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/abhishekkadian/anaconda/envs/py27/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;31m# TODO: add tests for operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m     \u001b[0m__radd__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size at /Users/soumith/anaconda/conda-bld/pytorch-0.1.8_1486027042839/work/torch/lib/TH/generic/THTensorMath.c:601"
     ]
    }
   ],
   "source": [
    "A + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "momentum_par = 0.5\n",
    "lr = 0.01\n",
    "log_interval = 10\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader_kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1040b0e58>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "trainset_labeled = pickle.load(open(\"data/train_labeled.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validset = pickle.load(open(\"data/validation.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset_labeled, batch_size=64, shuffle=True, **loader_kwargs)\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 2.299089\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 2.287868\n",
      "Train Epoch: 1 [1280/3000 (43%)]\tLoss: 2.297804\n",
      "Train Epoch: 1 [1920/3000 (64%)]\tLoss: 2.294657\n",
      "Train Epoch: 1 [2560/3000 (85%)]\tLoss: 2.312828\n",
      "\n",
      "Test set: Average loss: 2.2745, Accuracy: 2731/10000 (27%)\n",
      "\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 2.295248\n",
      "Train Epoch: 2 [640/3000 (21%)]\tLoss: 2.292928\n",
      "Train Epoch: 2 [1280/3000 (43%)]\tLoss: 2.273643\n",
      "Train Epoch: 2 [1920/3000 (64%)]\tLoss: 2.223941\n",
      "Train Epoch: 2 [2560/3000 (85%)]\tLoss: 2.260562\n",
      "\n",
      "Test set: Average loss: 2.2152, Accuracy: 3900/10000 (39%)\n",
      "\n",
      "Train Epoch: 3 [0/3000 (0%)]\tLoss: 2.230175\n",
      "Train Epoch: 3 [640/3000 (21%)]\tLoss: 2.228118\n",
      "Train Epoch: 3 [1280/3000 (43%)]\tLoss: 2.249061\n",
      "Train Epoch: 3 [1920/3000 (64%)]\tLoss: 2.250877\n",
      "Train Epoch: 3 [2560/3000 (85%)]\tLoss: 2.228348\n",
      "\n",
      "Test set: Average loss: 2.0300, Accuracy: 4676/10000 (47%)\n",
      "\n",
      "Train Epoch: 4 [0/3000 (0%)]\tLoss: 2.055495\n",
      "Train Epoch: 4 [640/3000 (21%)]\tLoss: 2.049053\n",
      "Train Epoch: 4 [1280/3000 (43%)]\tLoss: 2.107830\n",
      "Train Epoch: 4 [1920/3000 (64%)]\tLoss: 1.912523\n",
      "Train Epoch: 4 [2560/3000 (85%)]\tLoss: 1.749580\n",
      "\n",
      "Test set: Average loss: 1.5252, Accuracy: 6254/10000 (63%)\n",
      "\n",
      "Train Epoch: 5 [0/3000 (0%)]\tLoss: 1.891008\n",
      "Train Epoch: 5 [640/3000 (21%)]\tLoss: 1.608718\n",
      "Train Epoch: 5 [1280/3000 (43%)]\tLoss: 1.442615\n",
      "Train Epoch: 5 [1920/3000 (64%)]\tLoss: 1.685202\n",
      "Train Epoch: 5 [2560/3000 (85%)]\tLoss: 1.280703\n",
      "\n",
      "Test set: Average loss: 1.1116, Accuracy: 6860/10000 (69%)\n",
      "\n",
      "Train Epoch: 6 [0/3000 (0%)]\tLoss: 1.532231\n",
      "Train Epoch: 6 [640/3000 (21%)]\tLoss: 1.350541\n",
      "Train Epoch: 6 [1280/3000 (43%)]\tLoss: 1.198667\n",
      "Train Epoch: 6 [1920/3000 (64%)]\tLoss: 1.180934\n",
      "Train Epoch: 6 [2560/3000 (85%)]\tLoss: 1.015192\n",
      "\n",
      "Test set: Average loss: 0.7582, Accuracy: 8227/10000 (82%)\n",
      "\n",
      "Train Epoch: 7 [0/3000 (0%)]\tLoss: 1.067891\n",
      "Train Epoch: 7 [640/3000 (21%)]\tLoss: 1.021399\n",
      "Train Epoch: 7 [1280/3000 (43%)]\tLoss: 1.077716\n",
      "Train Epoch: 7 [1920/3000 (64%)]\tLoss: 0.953008\n",
      "Train Epoch: 7 [2560/3000 (85%)]\tLoss: 0.862806\n",
      "\n",
      "Test set: Average loss: 0.5707, Accuracy: 8548/10000 (85%)\n",
      "\n",
      "Train Epoch: 8 [0/3000 (0%)]\tLoss: 0.811297\n",
      "Train Epoch: 8 [640/3000 (21%)]\tLoss: 0.836717\n",
      "Train Epoch: 8 [1280/3000 (43%)]\tLoss: 0.991145\n",
      "Train Epoch: 8 [1920/3000 (64%)]\tLoss: 0.826507\n",
      "Train Epoch: 8 [2560/3000 (85%)]\tLoss: 0.742558\n",
      "\n",
      "Test set: Average loss: 0.4746, Accuracy: 8743/10000 (87%)\n",
      "\n",
      "Train Epoch: 9 [0/3000 (0%)]\tLoss: 0.931103\n",
      "Train Epoch: 9 [640/3000 (21%)]\tLoss: 0.953969\n",
      "Train Epoch: 9 [1280/3000 (43%)]\tLoss: 0.624165\n",
      "Train Epoch: 9 [1920/3000 (64%)]\tLoss: 0.841652\n",
      "Train Epoch: 9 [2560/3000 (85%)]\tLoss: 0.693740\n",
      "\n",
      "Test set: Average loss: 0.4359, Accuracy: 8882/10000 (89%)\n",
      "\n",
      "Train Epoch: 10 [0/3000 (0%)]\tLoss: 0.916033\n",
      "Train Epoch: 10 [640/3000 (21%)]\tLoss: 0.781790\n",
      "Train Epoch: 10 [1280/3000 (43%)]\tLoss: 0.578069\n",
      "Train Epoch: 10 [1920/3000 (64%)]\tLoss: 0.939331\n",
      "Train Epoch: 10 [2560/3000 (85%)]\tLoss: 0.684393\n",
      "\n",
      "Test set: Average loss: 0.3795, Accuracy: 8985/10000 (90%)\n",
      "\n",
      "Train Epoch: 11 [0/3000 (0%)]\tLoss: 0.643175\n",
      "Train Epoch: 11 [640/3000 (21%)]\tLoss: 0.693560\n",
      "Train Epoch: 11 [1280/3000 (43%)]\tLoss: 0.486610\n",
      "Train Epoch: 11 [1920/3000 (64%)]\tLoss: 0.671655\n",
      "Train Epoch: 11 [2560/3000 (85%)]\tLoss: 0.592080\n",
      "\n",
      "Test set: Average loss: 0.3406, Accuracy: 9063/10000 (91%)\n",
      "\n",
      "Train Epoch: 12 [0/3000 (0%)]\tLoss: 0.508250\n",
      "Train Epoch: 12 [640/3000 (21%)]\tLoss: 0.753472\n",
      "Train Epoch: 12 [1280/3000 (43%)]\tLoss: 0.945878\n",
      "Train Epoch: 12 [1920/3000 (64%)]\tLoss: 0.349038\n",
      "Train Epoch: 12 [2560/3000 (85%)]\tLoss: 0.624938\n",
      "\n",
      "Test set: Average loss: 0.3276, Accuracy: 9059/10000 (91%)\n",
      "\n",
      "Train Epoch: 13 [0/3000 (0%)]\tLoss: 0.620390\n",
      "Train Epoch: 13 [640/3000 (21%)]\tLoss: 1.008023\n",
      "Train Epoch: 13 [1280/3000 (43%)]\tLoss: 0.569733\n",
      "Train Epoch: 13 [1920/3000 (64%)]\tLoss: 0.497160\n",
      "Train Epoch: 13 [2560/3000 (85%)]\tLoss: 0.655159\n",
      "\n",
      "Test set: Average loss: 0.3037, Accuracy: 9159/10000 (92%)\n",
      "\n",
      "Train Epoch: 14 [0/3000 (0%)]\tLoss: 0.432013\n",
      "Train Epoch: 14 [640/3000 (21%)]\tLoss: 0.446500\n",
      "Train Epoch: 14 [1280/3000 (43%)]\tLoss: 0.608804\n",
      "Train Epoch: 14 [1920/3000 (64%)]\tLoss: 0.420387\n",
      "Train Epoch: 14 [2560/3000 (85%)]\tLoss: 0.557223\n",
      "\n",
      "Test set: Average loss: 0.3110, Accuracy: 9141/10000 (91%)\n",
      "\n",
      "Train Epoch: 15 [0/3000 (0%)]\tLoss: 0.485885\n",
      "Train Epoch: 15 [640/3000 (21%)]\tLoss: 0.492967\n",
      "Train Epoch: 15 [1280/3000 (43%)]\tLoss: 0.572001\n",
      "Train Epoch: 15 [1920/3000 (64%)]\tLoss: 0.408054\n",
      "Train Epoch: 15 [2560/3000 (85%)]\tLoss: 0.603293\n",
      "\n",
      "Test set: Average loss: 0.2898, Accuracy: 9171/10000 (92%)\n",
      "\n",
      "Train Epoch: 16 [0/3000 (0%)]\tLoss: 0.596510\n",
      "Train Epoch: 16 [640/3000 (21%)]\tLoss: 0.474084\n",
      "Train Epoch: 16 [1280/3000 (43%)]\tLoss: 0.793442\n",
      "Train Epoch: 16 [1920/3000 (64%)]\tLoss: 0.472843\n",
      "Train Epoch: 16 [2560/3000 (85%)]\tLoss: 0.293028\n",
      "\n",
      "Test set: Average loss: 0.2806, Accuracy: 9242/10000 (92%)\n",
      "\n",
      "Train Epoch: 17 [0/3000 (0%)]\tLoss: 0.496492\n",
      "Train Epoch: 17 [640/3000 (21%)]\tLoss: 0.511772\n",
      "Train Epoch: 17 [1280/3000 (43%)]\tLoss: 0.440429\n",
      "Train Epoch: 17 [1920/3000 (64%)]\tLoss: 0.631299\n",
      "Train Epoch: 17 [2560/3000 (85%)]\tLoss: 0.600695\n",
      "\n",
      "Test set: Average loss: 0.2634, Accuracy: 9232/10000 (92%)\n",
      "\n",
      "Train Epoch: 18 [0/3000 (0%)]\tLoss: 0.335789\n",
      "Train Epoch: 18 [640/3000 (21%)]\tLoss: 0.650051\n",
      "Train Epoch: 18 [1280/3000 (43%)]\tLoss: 0.489162\n",
      "Train Epoch: 18 [1920/3000 (64%)]\tLoss: 0.601467\n",
      "Train Epoch: 18 [2560/3000 (85%)]\tLoss: 0.477103\n",
      "\n",
      "Test set: Average loss: 0.2484, Accuracy: 9283/10000 (93%)\n",
      "\n",
      "Train Epoch: 19 [0/3000 (0%)]\tLoss: 0.318559\n",
      "Train Epoch: 19 [640/3000 (21%)]\tLoss: 0.290992\n",
      "Train Epoch: 19 [1280/3000 (43%)]\tLoss: 0.622609\n",
      "Train Epoch: 19 [1920/3000 (64%)]\tLoss: 0.370836\n",
      "Train Epoch: 19 [2560/3000 (85%)]\tLoss: 0.390075\n",
      "\n",
      "Test set: Average loss: 0.2598, Accuracy: 9225/10000 (92%)\n",
      "\n",
      "Train Epoch: 20 [0/3000 (0%)]\tLoss: 0.501569\n",
      "Train Epoch: 20 [640/3000 (21%)]\tLoss: 0.298090\n",
      "Train Epoch: 20 [1280/3000 (43%)]\tLoss: 0.459261\n",
      "Train Epoch: 20 [1920/3000 (64%)]\tLoss: 0.473935\n",
      "Train Epoch: 20 [2560/3000 (85%)]\tLoss: 0.216143\n",
      "\n",
      "Test set: Average loss: 0.2401, Accuracy: 9306/10000 (93%)\n",
      "\n",
      "Train Epoch: 21 [0/3000 (0%)]\tLoss: 0.354947\n",
      "Train Epoch: 21 [640/3000 (21%)]\tLoss: 0.442521\n",
      "Train Epoch: 21 [1280/3000 (43%)]\tLoss: 0.497173\n",
      "Train Epoch: 21 [1920/3000 (64%)]\tLoss: 0.598709\n",
      "Train Epoch: 21 [2560/3000 (85%)]\tLoss: 0.454156\n",
      "\n",
      "Test set: Average loss: 0.2269, Accuracy: 9355/10000 (94%)\n",
      "\n",
      "Train Epoch: 22 [0/3000 (0%)]\tLoss: 0.435476\n",
      "Train Epoch: 22 [640/3000 (21%)]\tLoss: 0.350050\n",
      "Train Epoch: 22 [1280/3000 (43%)]\tLoss: 0.354537\n",
      "Train Epoch: 22 [1920/3000 (64%)]\tLoss: 0.431475\n",
      "Train Epoch: 22 [2560/3000 (85%)]\tLoss: 0.383385\n",
      "\n",
      "Test set: Average loss: 0.2275, Accuracy: 9311/10000 (93%)\n",
      "\n",
      "Train Epoch: 23 [0/3000 (0%)]\tLoss: 0.461237\n",
      "Train Epoch: 23 [640/3000 (21%)]\tLoss: 0.358045\n",
      "Train Epoch: 23 [1280/3000 (43%)]\tLoss: 0.516747\n",
      "Train Epoch: 23 [1920/3000 (64%)]\tLoss: 0.651740\n",
      "Train Epoch: 23 [2560/3000 (85%)]\tLoss: 0.367094\n",
      "\n",
      "Test set: Average loss: 0.2258, Accuracy: 9339/10000 (93%)\n",
      "\n",
      "Train Epoch: 24 [0/3000 (0%)]\tLoss: 0.438994\n",
      "Train Epoch: 24 [640/3000 (21%)]\tLoss: 0.393352\n",
      "Train Epoch: 24 [1280/3000 (43%)]\tLoss: 0.327232\n",
      "Train Epoch: 24 [1920/3000 (64%)]\tLoss: 0.595375\n",
      "Train Epoch: 24 [2560/3000 (85%)]\tLoss: 0.639806\n",
      "\n",
      "Test set: Average loss: 0.2167, Accuracy: 9376/10000 (94%)\n",
      "\n",
      "Train Epoch: 25 [0/3000 (0%)]\tLoss: 0.405415\n",
      "Train Epoch: 25 [640/3000 (21%)]\tLoss: 0.557187\n",
      "Train Epoch: 25 [1280/3000 (43%)]\tLoss: 0.331344\n",
      "Train Epoch: 25 [1920/3000 (64%)]\tLoss: 0.448706\n",
      "Train Epoch: 25 [2560/3000 (85%)]\tLoss: 0.612010\n",
      "\n",
      "Test set: Average loss: 0.2154, Accuracy: 9343/10000 (93%)\n",
      "\n",
      "Train Epoch: 26 [0/3000 (0%)]\tLoss: 0.366465\n",
      "Train Epoch: 26 [640/3000 (21%)]\tLoss: 0.190277\n",
      "Train Epoch: 26 [1280/3000 (43%)]\tLoss: 0.493690\n",
      "Train Epoch: 26 [1920/3000 (64%)]\tLoss: 0.370293\n",
      "Train Epoch: 26 [2560/3000 (85%)]\tLoss: 0.432301\n",
      "\n",
      "Test set: Average loss: 0.2081, Accuracy: 9387/10000 (94%)\n",
      "\n",
      "Train Epoch: 27 [0/3000 (0%)]\tLoss: 0.283261\n",
      "Train Epoch: 27 [640/3000 (21%)]\tLoss: 0.364902\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-06793d768fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e27d239bf004>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishekkadian/anaconda/envs/py27/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    157\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishekkadian/anaconda/envs/py27/lib/python2.7/site-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     46\u001b[0m         grad_weight, grad_bias = (\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             if any(self.needs_input_grad[1:]) else (None, None))\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishekkadian/anaconda/envs/py27/lib/python2.7/site-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36m_grad_params\u001b[0;34m(self, input, weight, bias, grad_output)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grad_params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mthnn_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishekkadian/anaconda/envs/py27/lib/python2.7/site-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36m_thnn\u001b[0;34m(self, fn_name, input, weight, *args)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_thnn_convs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishekkadian/anaconda/envs/py27/lib/python2.7/site-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36mcall_grad_params\u001b[0;34m(self, bufs, input, weight, bias, grad_output)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         getattr(backend, fn.name)(backend.library_state, input, grad_output,\n\u001b[0;32m--> 255\u001b[0;31m                                   grad_weight, grad_bias, *args)\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_grad_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in valid_loader:\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target).data[0]\n",
    "    pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data).cpu().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss /= len(valid_loader) # loss function already averages over batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1939, Accuracy: 9438/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9438"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader.dataset) - correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for visualizing incorrectly classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "i = 0\n",
    "i_limit = 1\n",
    "\n",
    "# Pixel information for incorrectly classified images\n",
    "incorrect_pixels = []\n",
    "# Predictions made by network for incorrectly classified images\n",
    "incorrect_preds = []\n",
    "# Actual labels for incorrectly classified images\n",
    "incorrect_outputs = []\n",
    "\n",
    "for data, target in valid_loader:\n",
    "    if i == i_limit:\n",
    "        break\n",
    "    i += 1\n",
    "    if use_cuda:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target).data[0]\n",
    "    \n",
    "    pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "    mask = (pred != target.data)\n",
    "    incorrect_preds += list(pred[mask])\n",
    "    incorrect_outputs += list(target.data[mask].numpy())\n",
    "    incorrect_pixels += list(data.data.numpy()[target.data[mask].numpy()])\n",
    "    correct += pred.eq(target.data).cpu().sum()\n",
    "    \n",
    "incorrect_pixels = [torch.FloatTensor(x) for x in incorrect_pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    if type(img) == torch.FloatTensor:\n",
    "        npimg = img.numpy()\n",
    "    else:\n",
    "        npimg = img\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))[:,:,0], \n",
    "               cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAABnCAYAAADlhPAnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111680b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Images\")\n",
    "imshow(torchvision.utils.make_grid(incorrect_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [4, 4, 1, 7, 2, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted labels:\", incorrect_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels: [9, 8, 8, 9, 3, 3, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual labels:\", incorrect_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
