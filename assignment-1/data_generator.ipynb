{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "# from torch.autograd import Variable\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/fig/mnist.py\n",
    "def rotate_image(image, theta = 0.5):\n",
    "    rot_image = np.zeros((28,28))\n",
    "    def to_xy(j, k):\n",
    "        return (k-13, -j+14) # x range: -13..14, y range: -13..14\n",
    "    def to_jk(x, y):\n",
    "        return (-y+14, x+13)\n",
    "    def image_value(image, x, y):\n",
    "        j, k = to_jk(x, y)\n",
    "        return image[j, k]\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            x, y = to_xy(j, k)\n",
    "            x1 = np.cos(theta)*x + np.sin(theta)*y\n",
    "            y1 = -np.sin(theta)*x + np.cos(theta)*y\n",
    "\n",
    "            x2 = np.floor(x1)\n",
    "            delta_x = x1-x2\n",
    "            y2 = np.floor(y1)\n",
    "            delta_y = y1-y2\n",
    "\n",
    "            if x2 < -13 or x2 > 13 or y2 < -13 or y2 > 13: continue\n",
    "            value \\\n",
    "                = (1-delta_x)*(1-delta_y)*image_value(image, x2, y2)+\\\n",
    "                (1-delta_x)*delta_y*image_value(image, x2, y2+1)+\\\n",
    "                delta_x*(1-delta_y)*image_value(image, x2+1, y2)+\\\n",
    "                delta_x*delta_y*image_value(image, x2+1, y2+1)  \n",
    "#             rot_image[j, k] = 1.3*value\n",
    "            rot_image[j, k] = int(value)# int(1.3*value)\n",
    "    return rot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/chsasank/4d8f68caf01f041a6453e67fb30f8f5a\n",
    "\"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    ".. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "   Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "   Proc. of the International Conference on Document Analysis and\n",
    "   Recognition, 2003.\n",
    "\"\"\"\n",
    "\n",
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    assert len(image.shape)==2\n",
    "\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(42)\n",
    "\n",
    "    shape = image.shape\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "    indices = np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1))\n",
    "    \n",
    "#     return map_coordinates(image, indices, order=1).reshape(shape)\n",
    "    img = map_coordinates(image, indices, order=1).reshape(shape)\n",
    "    img_max = np.max(img)\n",
    "    scale = 255.0-img_max\n",
    "    return np.array([np.array([x + (x/255.0 * scale) for x in y]) for y in img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    if isinstance(img, torch.ByteTensor):\n",
    "        img = img.numpy()\n",
    "    if img.shape[0] > 784:\n",
    "        img = img.reshape(28,28)\n",
    "    \n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grey_inverse(img):\n",
    "    new_img = []\n",
    "    for x in img:\n",
    "        new_img.append(255.0-x)\n",
    "    return np.array(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALPHA = 36\n",
    "SIGMA = (4.0, 5.0, 6.0, 7.0)\n",
    "# ROTATIONS = (-0.4, -0.2, 0.2, 0.4)\n",
    "ROTATIONS = (-0.50, -0.3, 0.3, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "trainset_labeled = pickle.load(open(\"data/train_labeled.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alex/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n"
     ]
    }
   ],
   "source": [
    "new_train_data = []\n",
    "new_train_labels = []\n",
    "\n",
    "count = 0\n",
    "for img, val in zip(trainset_labeled.train_data, trainset_labeled.train_labels):\n",
    "    if count % 10 == 0:\n",
    "        print count\n",
    "    count += 1\n",
    "    img = img.numpy()\n",
    "    new_train_data.append(img)\n",
    "    new_train_labels.append(val)\n",
    "\n",
    "    for theta in ROTATIONS:\n",
    "        new_train_data.append(rotate_image(img, theta)) \n",
    "        new_train_labels.append(val)\n",
    "\n",
    "    for sigma in SIGMA:\n",
    "        img2 = elastic_transform(img, ALPHA, sigma)\n",
    "        new_train_data.append(img2)\n",
    "        new_train_labels.append(val)\n",
    "\n",
    "        for theta in ROTATIONS:\n",
    "            new_train_data.append(rotate_image(img2, theta))        \n",
    "            new_train_labels.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "for img, val in zip(new_train_data, new_train_labels):\n",
    "    imshow(img/255.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_data = np.array([(x.flatten()/255.0).reshape(1,28,28) for x in new_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_train_labels = np.array(new_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_train_data, open('data/gen_norm_train_data_75k.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_train_labels, open('data/gen_norm_train_labels_75k.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
